## step1 얼굴 사진 찍어 100장 저장
```python
# 수정안
import cv2
import numpy as np
import os

def face_extractor(img):
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    faces = face_classifier.detectMultiScale(gray, 1.3, 5)
                              #  # scaleFactor=1.3, minNeighbors=5
    if len(faces) == 0:
        return None
    
    # Only considering the last detected face for now
    x, y, w, h = faces[-1]
    cropped_face = img[y:y+h, x:x+w]
    return cropped_face

face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

cap = cv2.VideoCapture(0)
if not cap.isOpened():
    print("Error: Couldn't open the webcam.")
    exit()
count = 0

# Ensure "faces" directory exists
if not os.path.exists('faces'):
    os.makedirs('faces')

while True:
    ret, frame = cap.read()
    face = face_extractor(frame)
    
    if face is not None:
        count += 1
        face_resized = cv2.resize(face, (200, 200))
        face_gray = cv2.cvtColor(face_resized, cv2.COLOR_BGR2GRAY)
        file_name_path = 'faces/user' + str(count) + '.jpg'
        cv2.imwrite(file_name_path, face_gray)
      
        cv2.putText(frame, str(count), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 2)
        cv2.imshow('Face Cropper', face)
    #cv2.imshow('Face Cropper', frame)

    if cv2.waitKey(1) == ord('q') or count == 100:
        break
        
cap.release()
cv2.destroyAllWindows()
print('데이터 수집이 완료되었습니다!!!')
```

## step 2 - 100장 사진 학습
```python
# 코드 수정안 - 함수 미 사용
import cv2
import numpy as np
from os import listdir
from os.path import isfile, join

data_path = 'faces/'
# faces 폴더에 있는 파일 리스트 얻기
onlyfiles = [f for f in listdir(data_path) if isfile(join(data_path, f))]

# 데이터와 매칭될 라벨 변수
Training_Data, Labels = [], []

# 파일 개수 만큼 반복하기
for i, files in enumerate(onlyfiles):
    image_path = data_path + onlyfiles[i]

    images = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    # 이미지 파일이 아니거나 못 읽어 왔다면 무시
    if images is None:
        continue

    # Training_Data 리스트에 이미지를 바이트 배열로 추가
    Training_Data.append(np.asarray(images, dtype=np.uint8))
    # Labels 리스트에 카운트 번호 추가
    Labels.append(0)

print(Labels)
# 훈련할 데이터가 없다면 종료.
if len(Labels) == 0:
    print("There is no data to train.")
    exit()

# Labels를 32비트 정수로 변환
Labels = np.asarray(Labels, dtype=np.int32)

# 모델 생성
model = cv2.face.LBPHFaceRecognizer_create()

# 학습 시작
model.train(Training_Data, Labels)
print("모델 훈련이 완료되었습니다!!!!!")
```

```python
# 코드 수정안 - 함수사용
import cv2
import numpy as np
from os import listdir
from os.path import isfile, join

def load_images_from_path(data_path):
    onlyfiles = [f for f in listdir(data_path) if isfile(join(data_path, f))]
    training_data, labels = [], []

    for i, file in enumerate(onlyfiles):    
        image_path = join(data_path, file)
        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)

        if image is None:
            continue    

        training_data.append(np.asarray(image, dtype=np.uint8))
        labels.append(i)

    return training_data, labels

def train_model(training_data, labels):
    if len(labels) == 0:
        print("There is no data to train.")
        exit()

    labels = np.asarray(labels, dtype=np.int32)
    model = cv2.face.LBPHFaceRecognizer_create()
    model.train(np.asarray(training_data), np.asarray(labels))
    return model

data_path = 'faces/'
training_data, labels = load_images_from_path(data_path)
model = train_model(training_data, labels)
print("모델 훈련이 완료되었습니다!!!!!")
```

## step 3 - 얼굴 인식

```python
## haarcascade 다음 셀로 코드 변환
import cv2
import numpy as np
from os import listdir
from os.path import isfile, join

face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

def face_detector(img, size=0.5):
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
 
    faces = face_classifier.detectMultiScale(gray, 1.3, 5)                       
       
    if len(faces) == 0:
        return img, []
    
    for (x, y, w, h) in faces:
        cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 255), 2)
        roi = img[y:y+h, x:x+w]
        roi = cv2.resize(roi, (200, 200))
    return img, roi

cap = cv2.VideoCapture(0)

while True:
    ret, frame = cap.read()
    image, face = face_detector(frame)
    
    try:
        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)
        result = model.predict(face)
        print("result", result)
        
        if result[1] < 50:
            confidence = int(100 * (1 - (result[1] / 300)))
            display_string = str(confidence) + '% Confidence it is user'
            cv2.putText(image, display_string, (100, 120), cv2.FONT_HERSHEY_COMPLEX, 1, (250, 120, 255), 2)
            
            if confidence > 75:
                cv2.putText(image, "ACCESS GRANTED", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 2)
            else:
                cv2.putText(image, "ACCESS DENIED", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 0, 255), 2)
                
            cv2.imshow('Face Cropper', image)
            
    except:
        cv2.putText(image, "Face Not Found", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 0, 0), 2)
        cv2.imshow('Face Cropper', image)
    
    if cv2.waitKey(1) == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
```

# v2. 여러명 사진 찍어 누구인지
## step 1 - 사진찍어 database 생성
```python
# Step1 : 데이터 수집하기
import cv2
import os

cam = cv2.VideoCapture(0)
cam.set(3, 640) # set video width
cam.set(4, 480) # set video height

face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

# For each person, enter one numeric face id

face_id = input('\n 사용자 ID(예: 1, 2, 3... 숫자로)를 입력하고 enter 키를 누르세요 ==>  ')
if not os.path.exists('faces_m'):
    os.makedirs('faces_m')

print("\n 얼굴 캡쳐를 하기 위해 초기화 하고 있습니다. 카메라를 보고 기다려주세요.")

# 샘플링한 얼굴 캡쳐 사진 숫자 저장변수
count = 0

while(True):

    ret, img = cam.read()
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    faces = face_classifier.detectMultiScale(gray, 1.3, 5)

    for (x,y,w,h) in faces:

        cv2.rectangle(img, (x,y), (x+w,y+h), (255,0,0), 2)     
        count += 1

        # Save the captured image into the datasets folder
        cv2.imwrite("faces_m/User." + str(face_id) + '.' + str(count) + ".jpg", gray[y:y+h,x:x+w])
        
        cv2.putText(img, str(count), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 2)
        cv2.imshow('image', img)
           
    if cv2.waitKey(1) == ord('q') or count == 100:
        break

print("\n 데이터 수집이 완료되었습니다.")
cam.release()
cv2.destroyAllWindows()
```

## step 2 - faces_m 폴더의 사진 이용 얼굴 학습 - LBP 모델 사용
```python
# Step2 : 데이터 학습

import cv2
import numpy as np
from PIL import Image # pillow package
import os

# 얼굴 이미지 저장 경로
path = 'faces_m'

face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
model_LBPH = cv2.face.LBPHFaceRecognizer_create()

# function to get the images and label data
def getImagesAndLabels(path):

    imagePaths = [os.path.join(path,f) for f in os.listdir(path)]     
    faceSamples=[]
    ids = []

    for imagePath in imagePaths:

        PIL_img = Image.open(imagePath).convert('L') # convert it to grayscale
        img_numpy = np.array(PIL_img,'uint8')

        id = int(os.path.split(imagePath)[-1].split(".")[1])
        faces = face_classifier.detectMultiScale(img_numpy)

        for (x,y,w,h) in faces:
            faceSamples.append(img_numpy[y:y+h,x:x+w])
            ids.append(id)

    return faceSamples,ids

print ("\n 얼굴을 학습하고 있습니다. 시간이 조금 걸립니다. 기다려주세요 ...")
faces,ids = getImagesAndLabels(path)
model_LBPH.train(faces, np.array(ids))

if not os.path.exists('trainer'):
    os.makedirs('trainer')

# Save the model into trainer/trainer.yml
model_LBPH.write('trainer/trainer.yml') # recognizer.save() worked on Mac, but not on Pi

# Print the numer of faces trained and end program
print("\n {0} 명의 얼굴 학습이 완료되었습니다".format(len(np.unique(ids))))
```

## step 3 - 학습 바탕 현재 얼굴 인식
```python
# Step3 : 얼굴 인식 - type1 ( 사용자 이름을 리스트에 저장)
import cv2
import numpy as np

face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
model = cv2.face.LBPHFaceRecognizer_create()
model.read('trainer/trainer.yml')

font = cv2.FONT_HERSHEY_SIMPLEX

id = 0
names = ['', 'heesook','woo', 'eunjin']

cam = cv2.VideoCapture(0)

while True:
    ret, img = cam.read()
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    
    faces = face_classifier.detectMultiScale(gray, 1.3, 5)

    for(x,y,w,h) in faces:
        cv2.rectangle(img, (x,y), (x+w,y+h), (0,255,0),2)
        id, confidence = model.predict(gray[y:y+h, x:x+w])

        if confidence < 55 :
            id = names[id]
        else:
            id = "unknown"
        
        confidence = "  {0}%".format(round(100-confidence))

        cv2.putText(img,str(id), (x+5,y-5),font,1,(255,255,255),2)
        cv2.putText(img,str(confidence), (x+5,y+h-5),font,1,(255,255,0),1)
    
    cv2.imshow('camera',img)
    if cv2.waitKey(1) == ord('q') : 
        break

cam.release()
cv2.destroyAllWindows()
```

```python
# Step3 : 얼굴 인식 - type2 ( 사용자 이름을 딕셔너리에 저장)
import cv2
import numpy as np

face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
model_LBPH = cv2.face.LBPHFaceRecognizer_create()
model_LBPH.read('trainer/trainer.yml')

font = cv2.FONT_HERSHEY_SIMPLEX

id_to_name = {0: 'unknown', 1: 'heesook', 2: 'woo', 3:'eunjin'}

cam = cv2.VideoCapture(0)

while True:
    ret, img = cam.read()
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    
    faces = face_classifier.detectMultiScale(gray, 1.3, 5)

    for(x,y,w,h) in faces:
        cv2.rectangle(img, (x,y), (x+w,y+h), (0,255,0),2)
        face_roi = gray[y:y + h, x:x + w]     # 얼굴 영역 추출
        
        predicted_id, confidence = model_LBPH.predict(face_roi)       
        
        if confidence < 55:
            name = id_to_name[predicted_id]
        else:
            name = "unknown"    
       
        confidence = "  {0}%".format(round(100-confidence))

        cv2.putText(img, str(name), (x+5,y-5),font,1,(255,255,255),2)
        cv2.putText(img, str(confidence), (x+5,y+h-5),font,1,(255,255,0),1)
    
    cv2.imshow('camera',img)
    
    if cv2.waitKey(1) == ord('q') : 
        break

cam.release()
cv2.destroyAllWindows()
```

에러 발생 시,
```python
!python -m pip install --upgrade pip  
!pip3 install scikit-build  
!pip install cmake!pip install --user opencv-contrib-python==4.6.0.66!pip install opencv-python-headless==4.8.1.78  
!pip install opencv-contrib-python==4.8.1.78
```

# From Tradition CV to Artifical Intelligence

## 데이터 가져오기
### 학습 용 데이터/ 레이블 데이터 만들기
### 특징 값 찾기
### 특징 값을 사용하여 KNN 알고리즘으로 예측

### 평가하기 (Classification Report 사용)

### 결과 해석하기




```python
import cv2
import numpy as np
import warnings
warnings.filterwarnings('ignore')


# 이미지를 메모리로 읽어 보겠습니다.
red_card = cv2.imread("[Dataset] Module 21 images/cardred_close.png")
green_card = cv2.imread("[Dataset] Module 21 images/cardgreen_close.png")
black_card = cv2.imread("[Dataset] Module 21 images/cardblack_close.png")
background = cv2.imread("[Dataset] Module 21 images/cardnone.png")

# 특성을 추출하는 함수 정의(평균 색상)
def averagecolor(image):
    return np.mean(image, axis=(0, 1))


print (averagecolor(red_card))

print (averagecolor(green_card))

print (red_card.shape)

print (green_card.shape)


# 분류를 위해 특성(평균 색상) 및 해당 레이블(빨간색/녹색/검정색/없음) 저장
trainX = []
trainY = []

# 카드들에 대해 반복하고 평균 색상 출력
for (card,label) in zip((red_card,green_card,black_card,background),("red","green","black","none")):
    print((label, averagecolor(card)))
    trainX.append(averagecolor(card))
    trainY.append(label)

print(trainX)
print(np.array(trainX).shape)      #3개의 채널이 배열에 저장되는 방식을 참고하십시오.

print(trainY)
print(np.array(trainY).shape)


new_card = cv2.imread("[Dataset] Module 21 images/test/16.png")
new_card_features = averagecolor(new_card)

calculated_distances = []
for card in (trainX):
    calculated_distances.append(np.linalg.norm(new_card_features-card))
    
print (calculated_distances)

print(trainY[np.argmin(calculated_distances)])

print(calculated_distances)

print(np.argmin(calculated_distances))

print(trainY)

print(trainY[np.argmin(calculated_distances)])

# 먼저 새로운 이미지를 메모리로 읽습니다.
new_card = cv2.imread("[Dataset] Module 21 images/test/36.png")
new_card_features = averagecolor(new_card)

# 새 이미지의 특성(평균 색상)과 알려진 이미지 특성 사이의 거리를 계산합니다.
calculated_distances = []
for card in (trainX):
    calculated_distances.append(np.linalg.norm(new_card_features-card))

# 다음은 가장 유사한 카드의 결과입니다:
print(trainY[np.argmin(calculated_distances)])

# 먼저 새로운 이미지를 메모리로 읽습니다.
new_card = cv2.imread("[Dataset] Module 21 images/test/56.png")
new_card_features = averagecolor(new_card)

# 새 이미지의 특성(평균 색상)과 알려진 이미지 특성 사이의 거리를 계산합니다.
calculated_distances = []
for card in (trainX):
    calculated_distances.append(np.linalg.norm(new_card_features-card))

# 다음은 가장 유사한 카드의 결과입니다:
print(trainY[np.argmin(calculated_distances)])

from sklearn.metrics import classification_report
# 테스트 이미지에 대한 진리표입니다. 이미지를 보려면 컴퓨터의 폴더를 여십시오.
realtestY = np.array(["black","black","black","black","black",
                     "red","red","red","red","red",
                     "green","green","green","green","green",
                     "none","none","none","none","none"])
def evaluateaccuracy(filenames,predictedY):
    predictedY = np.array(predictedY)
    if (np.sum(realtestY!=predictedY)>0):
        print ("Wrong Predictions: (filename, labelled, predicted) ")
        print (np.dstack([filenames,realtestY,predictedY]).squeeze()[(realtestY!=predictedY)])
    # 전체 예측의 백분율로 일치하는 (정확한) 예측을 계산합니다.
    return "Correct :"+ str(np.sum(realtestY==predictedY)) + ". Wrong: "+str(np.sum(realtestY!=predictedY)) + ". Correctly Classified: " + str(np.sum(realtestY==predictedY)*100/len(predictedY))+"%"

import os
path = "[Dataset] Module 21 images/test/"
predictedY = []
filenames = []
for filename in os.listdir(path):
    img = cv2.imread(path+filename)
    img_features = averagecolor(img)
    calculated_distances = []
    for card in (trainX):
        calculated_distances.append(np.linalg.norm(img_features-card))
    prediction = trainY[np.argmin(calculated_distances)]
    
    print (filename + ": " + prediction) # 추론을 출력합니다.
    filenames.append(filename)
    predictedY.append(prediction)

# 정확도 평가(sklearn 패키지는 유용한 보고서를 제공합니다)
print ()
print(classification_report(realtestY, predictedY))

# 정확도 평가(잘못 분류된 항목의 파일 이름을 출력하기 위한 자체 사용자 정의 메소드)
print ()
print (evaluateaccuracy(filenames,predictedY))


```
