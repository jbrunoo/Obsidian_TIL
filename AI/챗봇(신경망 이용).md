
```python
from keras.models import Sequential
from keras.losses import categorical_crossentropy
from keras.optimizers import SGD
from keras.layers import Dense
 
from numpy import argmax
import numpy as np
import re

X = ['Hi',
     'Hello',
     'How are you?',
     'I am making',
     'making',
     'working',
     'studying',
     'see you later',
     'bye',
     'goodbye']
     
Y = ['greeting',
     'greeting',
     'greeting',
     'busy',
     'busy',
     'busy',
     'busy',
     'bye',
     'bye',
     'bye']

# 텍스트 처리
# 알파벳과 숫자가 아닌 문자 제거
def remove_non_alpha_numeric_characters(sentence):
    new_sentence = ''
    for alphabet in sentence:
        if alphabet.isalpha() or alphabet == ' ':
            new_sentence += alphabet
    return new_sentence

# 공백, 기호 날림, 공백 여러개 있으면 공백 하나로 처리
def preprocess_data(X):
    X = [data_point.lower() for data_point in X]
    X = [remove_non_alpha_numeric_characters(
        sentence) for sentence in X]
    X = [data_point.strip() for data_point in X]
    X = [re.sub(' +', ' ',
                data_point) for data_point in X]
    return X

X = preprocess_data(X)

vocabulary = set()
for data_point in X:
    for word in data_point.split(' '):
        vocabulary.add(word)
# unique
vocabulary = list(vocabulary)

# 문서 벡터 생성
X_encoded = []

def encode_sentence(sentence):
    sentence = preprocess_data([sentence])[0]
    sentence_encoded = [0] * len(vocabulary)
    for i in range(len(vocabulary)):
        if vocabulary[i] in sentence.split(' '):
            sentence_encoded[i] = 1
    return sentence_encoded

X_encoded = [encode_sentence(sentence) for sentence in X]

classes = list(set(Y))

Y_encoded = []
for data_point in Y:
    data_point_encoded = [0] * len(classes)
    for i in range(len(classes)):
        if classes[i] == data_point:
            data_point_encoded[i] = 1
    Y_encoded.append(data_point_encoded)


# 훈련 데이터 및 테스트 데이터 생성
X_train = X_encoded
y_train = Y_encoded
X_test = X_encoded
y_test = Y_encoded


# 모델 훈련
model = Sequential()
model.add(Dense(units=64, activation='sigmoid',
                input_dim=len(X_train[0])))
model.add(Dense(units=len(y_train[0]), activation='softmax'))
model.compile(loss=categorical_crossentropy,
              optimizer=SGD(learning_rate=0.01,
                            momentum=0.9, nesterov=True))
model.fit(np.array(X_train), np.array(y_train), epochs=100, batch_size=16)

# 예측 목록 표시
predictions = [argmax(pred) for pred in model.predict(np.array(X_test))]

# 모델 평가
correct = 0
for i in range(len(predictions)):
    if predictions[i] == argmax(y_test[i]):
        correct += 1

print ("Correct:", correct)
print ("Total:", len(predictions))
```

```python
# 챗봇 테스트 (무한루프문임)
while True:
    print ("Enter a sentence")
    sentence = input()
    prediction= model.predict(np.array([encode_sentence(sentence)]))
    print (classes[argmax(prediction)])
```

```python
import numpy as np
while True:
    print ("Enter a sentence")
    sentence = input()
    # 프로그램 종료 조건
    if sentence == 'q':
        break
        
    prediction = model.predict(np.array([encode_sentence(sentence)]), verbose=0)
    predicted_class = classes[np.argmax(prediction)]
    confidence = np.max(prediction)
    
    print(f"Predicted intent: {predicted_class} (Confidence: {confidence:.2f})")
    
    if predicted_class == 'bye':
        print('Goodbye! See you next time!')
    elif predicted_class == 'busy':
        print('ah... all the best!')
    elif predicted_class == 'greeting':
        print('Hi!')
    
```

